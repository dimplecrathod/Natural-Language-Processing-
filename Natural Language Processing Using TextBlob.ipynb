{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing using TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob is a python library and offers a simple API to access its methods and perform basic NLP tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Setting up system\n",
    "Anaconda prompt:\n",
    "pip install -U textblob\n",
    "python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Tokenization:\n",
    "Refers to dividing text or sentence into a sequence of tokens, which roughly correspond to words.\n",
    "Steps:\n",
    "a. Create a textblob object and pass a string with it\n",
    "b. Call functions of textblob in order to do a specific task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(\"It is a sunny day today.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(\"It is a sunny day today. \\n It is the month of August.\")\n",
    "\n",
    "#tokenization into sentences\n",
    "blob.sentences\n",
    "\n",
    "#extracting only first sentence\n",
    "blob.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It\n",
      "is\n",
      "a\n",
      "sunny\n",
      "day\n",
      "today\n"
     ]
    }
   ],
   "source": [
    "#printing words of first sentence\n",
    "for words in blob.sentences[0].words:\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Noun Phrase Extraction\n",
    "Extracting only noun phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sunny day\n",
      "machine learning\n",
      "fantastic way\n",
      "business operations\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"It is a sunny day today.\")\n",
    "for np in blob.noun_phrases:\n",
    "    print(np)\n",
    "    \n",
    "blob = TextBlob(\"Machine Learning is a fantastic way to predict future of business operations.\")\n",
    "for np in blob.noun_phrases:\n",
    "    print(np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Part of Speech Tagging \n",
    "Part of speech tagging or grammatical tagging - method to mark words present in text on basis of its definition and context.\n",
    "It tells us whether a word is a noun or an adjective or a verb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine NN\n",
      "Learning NNP\n",
      "is VBZ\n",
      "a DT\n",
      "fantastic JJ\n",
      "way NN\n",
      "to TO\n",
      "predict VB\n",
      "future NN\n",
      "of IN\n",
      "business NN\n",
      "operations NNS\n"
     ]
    }
   ],
   "source": [
    "for words, tag in blob.tags:\n",
    "    print(words, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Words Inflection and Lemmatization \n",
    "Inflection is a process of word formation in which characters are added to the base form of a word to express grammatical meanings. \n",
    "Word inflection in TextBlob : Words tokenized from textblob can be easily changed into singular or plural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "important\n",
      "important\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"Machine Learning is a fantastic way to predict future of business operations. \\n It is important for engineers pursuing CS to learn the subject.\")\n",
    "print(blob.sentences[1].words[2])\n",
    "print(blob.sentences[1].words[2].singularize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Platforms'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TextBlob library also offers an in-build object known as Word. We create a word object and apply afunction directly to it.\n",
    "\n",
    "from textblob import Word\n",
    "w = Word('Platform')\n",
    "\n",
    "w.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machines\n",
      "ways\n",
      "futures\n",
      "businesses\n",
      "subjects\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'reach'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can also use tags to inflect a particular type of word\n",
    "\n",
    "for word,pos in blob.tags:\n",
    "    if pos == 'NN':\n",
    "        print(word.pluralize())\n",
    "        \n",
    "#Words can be lemmatized using the  lemmatize function\n",
    "\n",
    "w = Word('reaching')\n",
    "w.lemmatize(\"v\")  ## v here represents verb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. N- grams\n",
    "A combination of multiple words together are called N-Grams. N-grams (N > 1) are generally more informative as compared to words, and can be used as features for langauge modeling. \n",
    "N- grams can be easily accessed in TextBlob using the ngrams function, which returns a tuple of n successive words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine', 'Learning', 'is']\n",
      "['Learning', 'is', 'a']\n",
      "['is', 'a', 'fantastic']\n",
      "['a', 'fantastic', 'way']\n",
      "['fantastic', 'way', 'to']\n",
      "['way', 'to', 'predict']\n",
      "['to', 'predict', 'future']\n",
      "['predict', 'future', 'of']\n",
      "['future', 'of', 'business']\n",
      "['of', 'business', 'operations']\n",
      "['business', 'operations', 'It']\n",
      "['operations', 'It', 'is']\n",
      "['It', 'is', 'important']\n",
      "['is', 'important', 'for']\n",
      "['important', 'for', 'engineers']\n",
      "['for', 'engineers', 'pursuing']\n",
      "['engineers', 'pursuing', 'CS']\n",
      "['pursuing', 'CS', 'to']\n",
      "['CS', 'to', 'learn']\n",
      "['to', 'learn', 'the']\n",
      "['learn', 'the', 'subject']\n"
     ]
    }
   ],
   "source": [
    "for ngram in blob.ngrams(3):\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Sentiment Analysis \n",
    "Determining the attitude or emotion of writer, i.e whether it is positive or negative or neutral. \n",
    "The sentiment function of textblob returns two properties, polarity and subjectivity.\n",
    "\n",
    "Polarity is a float which lies in range of [-1,1] where 1 means positive statement and -1 means a negative statement. Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information. Subjectivity is also a float which lies in the range of of [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google's ML crash course is a great course to learn data science \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.8, subjectivity=0.75)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"Google's ML crash course is a great course to learn data science \")\n",
    "print(blob)\n",
    "blob.sentiment\n",
    "\n",
    "#We can see that polarity is 0.8, which means that the statement is positive and 0.75 subjectivity refers that mostly it is a public opinion and not a factual information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Spelling Correction :\n",
    "Spelling correction is a feature which can be accessed using the correct function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Machine Morning is a data science topic\")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob  = TextBlob(\"Machine Lerning is a dta science topic\")\n",
    "blob.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', 0.5666666666666667),\n",
       " ('ta', 0.2),\n",
       " ('da', 0.13333333333333333),\n",
       " ('dat', 0.06666666666666667),\n",
       " ('sta', 0.03333333333333333)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can also check list of suggested word and its confidence using the spellcheck function \n",
    "blob.words[4].spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Creating a short summary of a text: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text is about...\n",
      "communities\n",
      "platforms\n",
      "industries\n",
      "forums\n",
      "platforms\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "blob = TextBlob(\"Analytics Vidhya is a thriving community for data driven industry. This platform allows people to know more about analytics from its articles, Q&A forum and learning paths. Also professionals and amateurs are able to sharpen their skillsets by providing a platform to participate in hackathons.\")\n",
    "\n",
    "nouns = list()\n",
    "\n",
    "for word, tag in blob.tags:\n",
    "    if tag == 'NN':\n",
    "        nouns.append(word.lemmatize())\n",
    "\n",
    "print(\"This text is about...\")\n",
    "for item in random.sample(nouns, 5):\n",
    "    word = Word(item)\n",
    "    print(word.pluralize())\n",
    "    \n",
    "    \n",
    "#What we did above that we extracted out a list of nouns from the text to give a general idea to the reader about the things the text is related to.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Translation and Language Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"good morning.\")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"صباح الخير. \")\n",
    "blob.detect_language()\n",
    "\n",
    "#Arabic\n",
    "\n",
    "#Translating it to English\n",
    "blob.translate(from_lang = 'ar', to = 'en')\n",
    "\n",
    "#Even if you don’t explicitly define the source language, TextBlob will automatically detect the language and translate into the desired language.\n",
    "blob.translate(to = 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Text Classification using TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Most Informative Features\n",
      "            contains(is) = True              neg : pos    =      2.9 : 1.0\n",
      "         contains(never) = False             neg : pos    =      1.8 : 1.0\n",
      "             contains(a) = False             neg : pos    =      1.8 : 1.0\n",
      "      contains(terrible) = False             neg : pos    =      1.8 : 1.0\n",
      "      contains(director) = False             pos : neg    =      1.4 : 1.0\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "training = [ \n",
    "('Tom Holland is a terrible spiderman.', 'pos'),\n",
    "('a terrible Javert (Russell Crowe) ruined Les Miserables for me...','pos'),\n",
    "('The Dark Knight Rises is the greatest superhero movie ever!','neg'),\n",
    "('Fantastic Four should have never been made.','pos'),\n",
    "('Wes Anderson is my favorite director!','neg'),\n",
    "('Captain America 2 is pretty awesome.','neg'),\n",
    "('Let\\s pretend \"Batman and Robin\" never happened..','pos'),\n",
    "]\n",
    "\n",
    "testing = [\n",
    "    ('Superman was never an interesting character.','pos'),\n",
    "('Fantastic Mr Fox is an awesome film!','neg'),\n",
    "('Dragonball Evolution is simply terrible!!','pos')\n",
    "]\n",
    "\n",
    "\n",
    "#Textblob provides in-build classifier module to create a custom classifier.\n",
    "\n",
    "from textblob import classifiers\n",
    "\n",
    "classifier = classifiers.NaiveBayesClassifier(training)\n",
    "\n",
    "#Textblob also offers Decision Tree Classifier along with Naive Bayes Classifier\n",
    "\n",
    "dt_classifier = classifiers.DecisionTreeClassifier(training)\n",
    "\n",
    "#Checking the accuracy of classifier on testing dataset\n",
    "\n",
    "print(classifier.accuracy(testing))\n",
    "\n",
    "#Textblob also provides most informative features\n",
    "classifier.show_informative_features(5)\n",
    "\n",
    "# We can see that if the text contains “is”, then there is a high probability that the statement will be negative.\n",
    "\n",
    "#Checking classifier on a random text\n",
    "\n",
    "blob = TextBlob('the weather is terrible!', classifier=classifier)\n",
    "print (blob.classify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros and Cons of TextBlob :\n",
    "Pros:\n",
    "Since, it is built on the shoulders of NLTK and Pattern, therefore making it simple for beginners by providing an intuitive interface to NLTK.\n",
    "It provides language translation and detection which is powered by Google Translate ( not provided with Spacy).\n",
    "Cons:\n",
    "It is little slower in the comparison to spacy but faster than NLTK. (Spacy > TextBlob > NLTK)\n",
    "It does not provide features like dependency parsing, word vectors etc. which is provided by spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"achi\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1 = TextBlob(\"Machine Learning\")\n",
    "string1[1:5] ##extracting 1 to 5 letters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
